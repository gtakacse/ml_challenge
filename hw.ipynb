{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  (1367, 4)\n",
      "Test set:  (586, 4)\n",
      "Recall: 0.717607973421927\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "data = []\n",
    "\n",
    "# Betöltés\n",
    "# kódolási séma specifikálása\n",
    "with open('data.csv','r', encoding='utf-8-sig') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    for item in csvreader:\n",
    "        data.append([ item['DATE'], item['AUTHOR'], item['CONTENT'], item['CLASS'] ])\n",
    "\n",
    "# A 'data' tömb elemei: ['dátum string', 'szerző', 'komment', 'osztály cimke ('0': nem spam, '1': spam)']\n",
    "        \n",
    "# Train/test szétválasztás\n",
    "split = 0.7\n",
    "data = np.asarray(data)\n",
    "perm = np.random.permutation(len(data))\n",
    "\n",
    "train = data[perm][0:int(len(data)*split)]\n",
    "test = data[perm][int(len(data)*split):]\n",
    "\n",
    "print('Train set: ', np.shape(train))\n",
    "print('Test set: ', np.shape(test))\n",
    "\n",
    "# Buta osztályozó\n",
    "def dumb_classify(data):\n",
    "    threshold = 0.3\n",
    "    if random.random() > threshold:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "\n",
    "# Használd a 'train' adatokat az osztályozó módszer kidolgozására, a 'test' adatokat kiértékelésére!\n",
    "# Lehetőleg használj gépi tanulást!\n",
    "# Dokumentáld az érdekesnek tartott kísérleteket is!\n",
    "\n",
    "# Példa kiértékelés 'recall' számításával. \n",
    "# Kérdés: Milyen egyéb metrikát használnál kiértékelésre és miért? \n",
    "sum_positive = 0\n",
    "found_positive = 0\n",
    "\n",
    "for datapoint in test:\n",
    "    if datapoint[-1] == '1':\n",
    "        sum_positive += 1\n",
    "        if dumb_classify(datapoint) == '1':\n",
    "            found_positive += 1\n",
    "    \n",
    "print('Recall:', found_positive / sum_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importálandó modulok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "stemmer = EnglishStemmer()\n",
    "stp_wrds = set(stopwords.words('english') + [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Előfeldolgozás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train, columns=[\"date\", \"author\", \"text\", \"spam\"])\n",
    "test_df = pd.DataFrame(test, columns=[\"date\", \"author\", \"text\", \"spam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_word(word):\n",
    "    # szamok helyettesitese\n",
    "    if re.match(r'\\d+', word) is not None:\n",
    "        return '$'\n",
    "    # emoji es smiley helyettesítése\n",
    "    elif re.match(r'(?::|;|=)(?:-)?(?:\\)|D|P|\\()', word) is not None or word in emoji.UNICODE_EMOJI:\n",
    "        return 'EMOJI'\n",
    "    # url linkek helyettesítése\n",
    "    elif re.match(r'((http|https):\\/\\/)?([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])?', word) is not None:\n",
    "        return 'URL'\n",
    "    else:\n",
    "        # írásjelek eltávolítása a felkiáltójelek kivételével\n",
    "        out = re.sub(r'[^A-Za-z0-9!]', '', word)\n",
    "        # ha egy betű egymás utan több, mint háromszor szerepel egy szóban, akkor valószínűleg emfatikus a használata\n",
    "        # pl. woooowwwwwwww\n",
    "        # ezeket egyetlen betűre cserélem\n",
    "        out = re.sub(r'(.)\\1+', r'\\1', out)\n",
    "        # stemmelés\n",
    "        return stemmer.stem(out)\n",
    "    \n",
    "def preprocessor(comment_text):\n",
    "    # \\ufeff karakterek eltűntetése\n",
    "    clean_text = comment_text.replace('\\ufeff', ' ')\n",
    "    # html kódok eltűntetése\n",
    "    clean_text = re.sub(r'<br\\s*\\/*>', ' ', clean_text)\n",
    "    # kisbetűsítés és tokenizálás\n",
    "    token_list = tokenizer.tokenize(clean_text.lower())\n",
    "    # előfeldolgozás, címkékre cserélés, stemmelés\n",
    "    p_token_list = [process_word(word) for word in token_list]\n",
    "    # stopword szavak eltávolítása\n",
    "    return [item for item in p_token_list if item not in stp_wrds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egy példa a preprocesszor működéséről\n",
      "Eredeti komment:\n",
      "Check out my Music Videos! Fuego - U LA LA Remix  hyperurl.co/k6a5xt﻿\n",
      "Előfeldolgozás utáni komment:\n",
      "['check', 'music', 'video', '!', 'fuego', 'u', 'la', 'la', 'remix', 'URL']\n"
     ]
    }
   ],
   "source": [
    "x = train_df['text'][3]\n",
    "print('Egy példa a preprocesszor működéséről')\n",
    "print('Eredeti komment:')\n",
    "print(x)\n",
    "print('Előfeldolgozás utáni komment:')\n",
    "print(preprocessor(x))\n",
    "#preprocessor('HAHAA THIS DANCE IS TIGHTTTT<br /><br />I know :) !!!\"^*&^?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorizálás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vektorizálás először count vektorizátorral\n",
    "\"\"\"vectorizer = CountVectorizer(lowercase=False,\n",
    "                             ngram_range=(1, 1), \n",
    "                             analyzer=preprocessor, \n",
    "                             max_df=0.95, \n",
    "                             min_df=5, \n",
    "                             max_features=None)\n",
    "\"\"\"\n",
    "# tfidf vektorizátor\n",
    "vectorizer = TfidfVectorizer(lowercase=False,\n",
    "                            ngram_range=(1,1),\n",
    "                            analyzer=preprocessor,\n",
    "                            max_df=0.95,\n",
    "                            min_df=5)\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "y_train = train_df['spam'].map(lambda x: int(x))\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['spam'].map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering - extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Néhány spam komment kilistázása után feltűnt, hogy a spamok gyakran használnak nagybetűket, felkiáltójeleket. Hogy a tanítókorpuszban is megjelenjenek ezek a jellemzők 4 extra feature-t kiszámító funkciót írtam. Ezek a betűk arányát, a nagybetűk arányát, az írásjelek arányát és a posztolás idejét napszakra lebontva adják vissza. Az extra feature-öket a vektorizálás utáni mátrixokhoz fűztem hozzá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_char_ratios(comment):\n",
    "    if len(comment) < 1:\n",
    "        return (0, 0, 0)\n",
    "    # betűk aránya\n",
    "    lett_ratio = len(re.findall(r'[a-zA-Z]', comment))/len(comment)\n",
    "    # nagybetűk aránya\n",
    "    upper_ratio = len(re.findall(r'[A-Z]', comment))/len(comment)\n",
    "    # irasjelek aránya\n",
    "    punc_ratio = len(re.findall(r'[^a-zA-Z0-9\\s]', comment))/len(comment)\n",
    "    return (lett_ratio, upper_ratio, punc_ratio)\n",
    "    \n",
    "def deter_posting_time(date):\n",
    "    # talán a komment posztolásának ideje a spamok esetében eltér a normál felhasználók posztolási idejétől,\n",
    "    # ami főleg akkor lehet jelentős, ha a spam kommenteket gépek küldik\n",
    "    # posztolás ideje: 0 = NaN, 1 = hajnal, 2 = delelott, 3 = delutan, 4 = este \n",
    "    if len(date) < 1:\n",
    "        return 0\n",
    "    hour = int(re.search(r'T(\\d{2}):', date).groups()[0])\n",
    "    if hour < 6:\n",
    "        return 1\n",
    "    elif hour < 12:\n",
    "        return 2\n",
    "    elif hour < 18:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1367, 401) (586, 401)\n"
     ]
    }
   ],
   "source": [
    "# extra feature-ök hozzáadása a tanítóadatokhoz\n",
    "n = X_train.shape[1]\n",
    "feature_names = ['lett_ratio', 'upper_ratio', 'punc_ratio', 'posting_time']\n",
    "extra_train = train_df['text'].map(lambda x: calc_char_ratios(x))\n",
    "extra_train = extra_train.apply(pd.Series)\n",
    "extra_train[3] = train_df['date'].map(lambda x: deter_posting_time(x))\n",
    "X_train = hstack((X_train, extra_train))\n",
    "\n",
    "#update vecotorizer vocabulary\n",
    "for i in range(4):\n",
    "    vectorizer.vocabulary_[feature_names[i]] = n + i\n",
    "\n",
    "# extra feature-ök hozzáadása a tesztadatokhoz\n",
    "extra_test = test_df['text'].map(lambda x: calc_char_ratios(x))\n",
    "extra_test = extra_test.apply(pd.Series)\n",
    "extra_test[3] = test_df['date'].map(lambda x: deter_posting_time(x))\n",
    "X_test = hstack((X_test, extra_test))\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spamdetektálás egy klasszifikációs feladat, amelyet az irodolomban található eredmények szerint a Naív Bayes osztályozók kifejezetten jól képesek kezelni. A Naív Bayes-féle osztályozók továbbá kellően robosztusak, gyorsak és kevés tanulóadattal is jól működnek, így baseline modellként érdemes ezzel kezdeni.\n",
    "\n",
    "Mivel a nyelvi adatok feldolgozásához gyakorisági alapú vektorizálót használtam, így a naív Bayes osztályozók multinomiális változatát választottam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall a tanulóadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       665\n",
      "          1       0.97      0.93      0.95       702\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1367\n",
      "\n",
      "Recall a tesztadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.92       285\n",
      "          1       0.93      0.91      0.92       301\n",
      "\n",
      "avg / total       0.92      0.92      0.92       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_nb = MultinomialNB()\n",
    "multi_nb.fit(X_train, y_train)\n",
    "print('Recall a tanulóadatokon')\n",
    "print(classification_report(y_train, multi_nb.predict(X_train)))\n",
    "print('Recall a tesztadatokon')\n",
    "print(classification_report(y_test, multi_nb.predict(X_test)))\n",
    "# performance logs\n",
    "# CountVectorizer max_df 1.0, min_df 1, MN Naive Bayes (alpha 1), test set: 0 recall 0.84, 1 recall 0.95\n",
    "# CountVectorizer max_df 1.0, min_df 1, MN Naive Bayes (alpha 1) with extra features, test set: 0 recall 0.89, 1 recall 0.95\n",
    "# CountVectorizer max_df 0.95, min_df 5, MN Naive Bayes (alpha 1) with extra features, test set: 0 recall 0.96, 1 recall 0.88\n",
    "# TfidfVectorizer max_df 1.0, min_df 1, MN Naive Bayes (alpha 1) with extra features, test set: 0 recall 0.95, 1 recall 0.91\n",
    "# TfidfVectorizer max_df 0.95, min_df 5, MN Naive Bayes (alpha 1) with extra features, test set: 0 recall 0.93, 1 recall 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'alpha': 1}\n",
      "Recall a tanulóadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       665\n",
      "          1       0.97      0.93      0.95       702\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1367\n",
      "\n",
      "Recall a tesztadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.92       285\n",
      "          1       0.93      0.91      0.92       301\n",
      "\n",
      "avg / total       0.92      0.92      0.92       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alpha állítása - Grid Search Cross Validation\n",
    "mn_nb = MultinomialNB()\n",
    "params = {'alpha': [0.01, 0.1, 1, 2, 5, 10]}\n",
    "grid_CV = GridSearchCV(mn_nb, params, cv=10, refit=True)\n",
    "grid_CV.fit(X_train, y_train)\n",
    "print('Best alpha: {}'.format(grid_CV.best_params_))\n",
    "print('Recall a tanulóadatokon')\n",
    "print(classification_report(y_train, grid_CV.predict(X_train)))\n",
    "print('Recall a tesztadatokon')\n",
    "print(classification_report(y_test, grid_CV.predict(X_test)))\n",
    "# best model with TfidfVectorizer max_df 0.95, min_df 5, with extra featerus\n",
    "# MN_Bayes alpha 2, 0 recall on test dataset 0.94; 1 recall on test dataset 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Support Vector Machine algoritmusok ugyancsak jól szoktak szerepelni a szövegkategorizációs feladatokban, így a következő részben megnézem, hogy milyen pontossággal képesek a kommentek közül kiválogatni a spamokat. A Naív Bayes-féle modellek eddigi legjobbjai 94%-os recall értékek körül teljesítettek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10], 'degree': [2], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'class_weight': ['balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "svc_params = {'C': [0.01, 0.1, 1, 10],\n",
    "             'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'degree': [2],\n",
    "             'class_weight': ['balanced']}\n",
    "svc_grid = GridSearchCV(svc_model, svc_params, cv=10, refit=True)\n",
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1, 'degree': 2, 'kernel': 'linear', 'class_weight': 'balanced'}\n",
      "Recall a tanulóadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       665\n",
      "          1       0.99      0.95      0.97       702\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1367\n",
      "\n",
      "Recall a tesztadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       285\n",
      "          1       0.98      0.92      0.95       301\n",
      "\n",
      "avg / total       0.95      0.95      0.95       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(svc_grid.best_params_))\n",
    "print('Recall a tanulóadatokon')\n",
    "print(classification_report(y_train, svc_grid.predict(X_train)))\n",
    "print('Recall a tesztadatokon')\n",
    "print(classification_report(y_test, svc_grid.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az SVM klasszifikátor 1%-kal teljesít jobban, mint a Naív Bayes modell. Átlagosan a recall 95% a tesztadatokon. Mivel a legjobb eredményt a lineáris kernel érte el, így érdemes lehet logaritmikus regresszióval is ellenőrizni az eredményeket, hiszen a scikit-learn Logistic Regression moduljában be lehet állítani \"L1\" loss funkciót, míg az SVC-ben erre nincs lehetőség."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10], 'class_weight': ['balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "logreg_params = {'penalty': ['l1', 'l2'],\n",
    "                'C': [0.01, 0.1, 1, 10],\n",
    "                'class_weight': ['balanced']}\n",
    "logreg_grid = GridSearchCV(logreg_model, logreg_params, cv=10, refit=True)\n",
    "logreg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1, 'penalty': 'l2', 'class_weight': 'balanced'}\n",
      "Recall a tanulóadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95       665\n",
      "          1       0.98      0.93      0.95       702\n",
      "\n",
      "avg / total       0.96      0.95      0.95      1367\n",
      "\n",
      "Recall a tesztadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       285\n",
      "          1       0.97      0.91      0.94       301\n",
      "\n",
      "avg / total       0.94      0.94      0.94       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(logreg_grid.best_params_))\n",
    "print('Recall a tanulóadatokon')\n",
    "print(classification_report(y_train, logreg_grid.predict(X_train)))\n",
    "print('Recall a tesztadatokon')\n",
    "print(classification_report(y_test, logreg_grid.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habár a logaritmikus regresszió az \"L2\" loss funkcióval érte el a legjobb eredményt, a lineáris SVM-hez képest a modell 1%-kal jobban teljesít: átlagosan 96%-os pontosságál kategorizál a modell a teszthalmazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az utolsó modellként a Random Forest algoritmus teljesítményét tesztelem, amely a kategorizációs feladatokban jellemzően jól szokott teljesíteni.\n",
    "A Random Forest algoritmusok nagy hátránya, hogy sokáig tart tanítani őket. Mivel azonban a jelen adatbázis viszonylag kevés tanítóadatot tartalmaz, így remélhetőleg a random forest megbírkózik vele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'bootstrap': [True, False], 'min_samples_leaf': [1, 3, 10], 'min_samples_split': [1, 3, 10], 'max_depth': [3, None], 'criterion': ['gini', 'entropy'], 'max_features': [1, 3, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "rf_grid = GridSearchCV(rf_model, rf_grid, cv=10, refit=True)\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'criterion': 'entropy', 'min_samples_split': 10, 'max_features': 10}\n",
      "Recall a tanulóadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       665\n",
      "          1       1.00      1.00      1.00       702\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1367\n",
      "\n",
      "Recall a tesztadatokon\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       285\n",
      "          1       0.98      0.95      0.96       301\n",
      "\n",
      "avg / total       0.96      0.96      0.96       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(rf_grid.best_params_))\n",
    "print('Recall a tanulóadatokon')\n",
    "print(classification_report(y_train, rf_grid.predict(X_train)))\n",
    "print('Recall a tesztadatokon')\n",
    "print(classification_report(y_test, rf_grid.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eddig a Random Forest terjesített a legjobban, amely a tesztadatokon 96-97%-os recall pontossággal kategorizálta a spam és a nem spam kommenteket. Ez azt jelenti, hogy a 586 tesztpélda küzöl a Random Forest csak 20 kommentet kategorizált félre. Ezek az eredmények meglehetősen ígéretesek, így ha a minta reprezentatív a populációra nézve, a tanított modellek 95% fölötti pontossággal meg tudják állapítani egy adott kommentről, hogy spam vagy sem. Az osztályozók teljesítményét talán még 1-2%-kal lehetne javítani az előfeldozó és a extra feature-ök fejlesztésével."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
